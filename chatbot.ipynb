{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9057b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage,BaseMessage\n",
    "from dotenv import load_dotenv\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph.message import add_messages  \n",
    "import streamlit as st\n",
    "from langsmith import traceable\n",
    "import os\n",
    "#tool nodes\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bca5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm= ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c9319",
   "metadata": {},
   "source": [
    "#Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.tools import tool\n",
    "\n",
    "# prebuilt tool\n",
    "search_tool = DuckDuckGoSearchRun(region=\"us-en\")\n",
    "\n",
    "# custom calculator tool\n",
    "@tool\n",
    "def calculator(n1: float, n2: float, operation: str) -> dict:\n",
    "    \"\"\"\n",
    "    Perform mathematical operations on two numbers.\n",
    "    Supported operations: add, sub, mul, div\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if operation == \"add\":\n",
    "            result = n1 + n2\n",
    "        elif operation == \"sub\":\n",
    "            result = n1 - n2\n",
    "        elif operation == \"mul\":\n",
    "            result = n1 * n2\n",
    "        elif operation == \"div\":\n",
    "            if n2 == 0:\n",
    "                return {\"error\": \"division by zero not allowed\"}\n",
    "            result = n1 / n2\n",
    "        else:\n",
    "            return {\"error\": f'unsupported operation \"{operation}\"'}\n",
    "\n",
    "        return {\"n1\": n1, \"n2\": n2, \"operation\": operation, \"result\": result}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# custom stock price tool\n",
    "@tool\n",
    "def get_stock_price(symbol: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch the latest stock price for the given symbol (e.g., 'AAPL', 'TSLA')\n",
    "    using the Alpha Vantage API.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.alphavantage.co/query?function=GLOBAL_QUOTE&symbol={symbol}&apikey=6OEI5ZVB2RS2AECF\"\n",
    "    r = requests.get(url)   \n",
    "    return r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ca05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of all tools\n",
    "tools=[get_stock_price, calculator, search_tool]\n",
    "\n",
    "llm_with_tools=llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e53947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state:State):\n",
    "    messages=state['messages']\n",
    "    response=llm_with_tools.invoke(messages)\n",
    "    return {\"messages\":[response]}\n",
    "\n",
    "tool_node= ToolNode(tools) #execute tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph= StateGraph(State)\n",
    "graph.add_node(\"Chat Node\", chat_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "#edge\n",
    "graph.add_edge(START,\"Chat Node\")\n",
    "\n",
    "graph.add_conditional_edges(\"Chat Node\",tools_condition)\n",
    "graph.add_edge(\"tools\",\"Chat Node\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf9904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=chatbot.invoke({\"messages\":[HumanMessage(content=\"Hello\")]})\n",
    "print(out[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2134de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chatbot.invoke({\"messages\": [HumanMessage(content=\"What is the stock price of Apple?\")]})\n",
    "\n",
    "print(out[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2202d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = chatbot.invoke({\"messages\": [HumanMessage(content=\"What is the stock price of Apple?\")]})\n",
    "\n",
    "print(out[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8fbb3c5",
   "metadata": {},
   "source": [
    "### Human In the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, AnyMessage, BaseMessage\n",
    "from typing import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.types import interrupt, Command  #for Human in the loop\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01d2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm=ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e328db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state:State):\n",
    "    decision=interrupt(\n",
    "        {\n",
    "            \"type\":\"approvel\",\n",
    "            \"reason\":\"Model is about to answer user question\",\n",
    "            \"question\": state[\"messages\"][-1].content,\n",
    "            \"instructions\":\"Approve this question? yes/no\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if decision[\"approved\"]=='no':\n",
    "        return{\"messages\":[AIMessage(content=\"Not approved\")]}\n",
    "    \n",
    "    else:\n",
    "        response=llm.invoke(state[\"messages\"])\n",
    "        return {\"messages\":[response]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db727226",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(State)\n",
    "\n",
    "graph.add_node(\"chat node\", chat_node)\n",
    "\n",
    "graph.add_edge(START, \"chat node\")\n",
    "graph.add_edge(\"chat node\", END)\n",
    "\n",
    "checkpointer=InMemorySaver()\n",
    "workflow=graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c8a1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"thread_id\":\"123\"}}\n",
    "\n",
    "input_data = {\n",
    "    \"messages\": [\n",
    "        (\"user\", \"Explain gradient descent in simple terms\")\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "res = workflow.invoke(input_data, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3076134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Explain gradient descent in simple terms', additional_kwargs={}, response_metadata={}, id='2805ad6e-22c3-44df-b02d-d44705f55922')],\n",
       " '__interrupt__': [Interrupt(value={'type': 'approvel', 'reason': 'Model is about to answer user question', 'question': 'Explain gradient descent in simple terms', 'instructions': 'Approve this question? yes/no'}, id='0f34fd0c1fa91f5461569d076a7e2e93')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fb0ba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'approvel',\n",
       " 'reason': 'Model is about to answer user question',\n",
       " 'question': 'Explain gradient descent in simple terms',\n",
       " 'instructions': 'Approve this question? yes/no'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = res['__interrupt__'][0].value\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d751ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "message_user_input = input(f\" Backend Message --- {message}\\n Approve this question? (yes/no): \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa81dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_res=workflow.invoke(Command(resume={\"approved\":message_user_input}),config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "537a54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Explain gradient descent in simple terms', additional_kwargs={}, response_metadata={}, id='2805ad6e-22c3-44df-b02d-d44705f55922'), AIMessage(content='Gradient descent is an optimization algorithm used to minimize a function by iteratively moving in the direction of steepest descent, which is the negative of the gradient of the function. In simpler terms, it is like trying to find the bottom of a valley by taking small steps downhill and adjusting your direction based on the slope of the terrain. By repeating this process, the algorithm can ultimately find the minimum value of the function.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 14, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-ClvrVSCckx2pZBShRARBmtM43pbnc', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--dac6bb4d-23c6-4610-b534-45199b177617-0', usage_metadata={'input_tokens': 14, 'output_tokens': 84, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "print(final_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31829d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c406df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "423c8ad9",
   "metadata": {},
   "source": [
    "### SubGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53ca0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "029c83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input_text:str\n",
    "    translate_text: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5159c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_llm= ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97fcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(state: State):\n",
    "    prompt = f\"\"\"\n",
    "You are a translator. Translate the following text into Punjabi.\n",
    "Make sure it is accurate and point to point.\n",
    "\n",
    "Text:\n",
    "{state[\"input_text\"]}\n",
    "\"\"\".strip()\n",
    "\n",
    "    translate_text = subgraph_llm.invoke(prompt).content\n",
    "    return {\"translate_text\": translate_text}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451bb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_builder= StateGraph(State)\n",
    "subgraph_builder.add_node(\"translate\", translate)\n",
    "\n",
    "subgraph_builder.add_edge(START, \"translate\")\n",
    "subgraph_builder.add_edge(\"translate\", END)\n",
    "\n",
    "subgraph=subgraph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f56ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parent class\n",
    "class ParentState(TypedDict):\n",
    "    question:str\n",
    "    answer_gen:str\n",
    "    ans_punj:str "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783bc29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_llm= ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b915eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ans(state: ParentState):\n",
    "    answer=parent_llm.invoke(f\"You are a helful assistant. Answer clearly.\\n\\n Question: {state['question']}\").content\n",
    "    return {\"answer_gen\": answer}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1f6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(state:ParentState):\n",
    "    result=subgraph.invoke({'input_text': state[\"answer_gen\"]})\n",
    "    return {\"ans_punj\": result[\"translate_text\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7f06533",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_builder=StateGraph(ParentState)\n",
    "\n",
    "parent_builder.add_node(\"answer\", generate_ans)\n",
    "parent_builder.add_node(\"translator\",translator)\n",
    "\n",
    "parent_builder.add_edge(START,\"answer\")\n",
    "parent_builder.add_edge(\"answer\", \"translator\")\n",
    "parent_builder.add_edge(\"translator\", END)\n",
    "\n",
    "workflow=parent_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7d9316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is quantum physics?',\n",
       " 'answer_gen': 'Quantum physics is the branch of physics that studies the behavior of particles at a very small scale, such as atoms and subatomic particles. It involves principles such as quantization, wave-particle duality, and uncertainty. Quantum physics is different from classical physics in that it allows for the existence of superposition and entanglement among particles.',\n",
       " 'ans_punj': 'ਕਵੰਟਮ ਭੌਤਿਕੀ ਉਹ ਭੌਤਿਕੀ ਸ਼ਾਖਾ ਹੈ ਜੋ ਖੁੱਲ੍ਹੇ ਦਾ ਭਾਵ ਦਾ ਅਧਿਯਯਨ ਕਰਦੀ ਹੈ, ਜਿਵੇਂ ਕਿ ਪਰਮਾਣੂ ਅਤੇ ਉਪਪਰਮਾਣੂ ਕਣਾਂ ਦੀ ਚਾਲਾਂ। ਇਸ ਵਿਚ ਇਕੁਈਕਰਣ, ਤਰੰਗ-ਪਰਮਾਣੂ ਦੋਗਲਤਾ, ਅਤੇ ਅਨਿਯਤਤਾ ਦੀਆਂ ਸੰਜਣਾਂ ਸ਼ਾਮਲ ਹੁੰਦੀਆਂ ਹਨ। ਕਵੰਟਮ ਭੌਤਿਕੀ ਨੂੰ ਕਲਾਸੀਕਲ ਭੌਤਿਕੀ ਤੋਂ ਇੱਕ ਹੋਰ ਹੈ ਕਿ ਇਸ ਨੂੰ ਕਣਾਂ ਵਿੱਚ ਅਕਾਰਾਂ ਵੱਲੋਂ ਅਤੇ ਉਪਸਰਨਾਂ ਦੇ ਹੋਣ ਦੀ ਇਜ਼ਾਜ਼ਤ ਦਿੰਦਾ ਹੈ।'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke({\"question\":\"What is quantum physics?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5e519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df743f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2730977",
   "metadata": {},
   "source": [
    "### Shared state in Subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af50efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc71e03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6f189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446b3a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
